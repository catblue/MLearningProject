<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks" />


<title>CodeBook</title>

<script src="CodeBook_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="CodeBook_files/bootstrap-2.3.2/css/bootstrap.min.css" rel="stylesheet" />
<link href="CodeBook_files/bootstrap-2.3.2/css/bootstrap-responsive.min.css" rel="stylesheet" />
<script src="CodeBook_files/bootstrap-2.3.2/js/bootstrap.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="CodeBook_files/highlight/default.css"
      type="text/css" />
<script src="CodeBook_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">CodeBook</h1>
<h4 class="author"><em>Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks</em></h4>
<h4 class="date"><em>Wednesday, August 06, 2014</em></h4>
</div>


<div id="human-activity-recognition" class="section level3">
<h3>Human Activity Recognition</h3>
<p>Human Activity Recognition - HAR - has emerged as a key research area in the last years and is gaining increasing attention by the pervasive computing research community (see picture below, that illustrates the increasing number of publications in HAR with wearable accelerometers), especially for the development of context-aware systems. There are many potential applications for HAR, like: elderly monitoring, life log systems for monitoring energy expenditure and for supporting weight-loss programs, and digital assistants for weight lifting exercises.</p>
</div>
<div id="har-dataset-for-benchmarking" class="section level3">
<h3>HAR Dataset for benchmarking</h3>
<p>We propose a dataset with 5 classes (sitting-down, standing-up, standing, walking, and sitting) collected on 8 hours of activities of 4 healthy subjects. We also established a baseline performance index. You can download the dataset here (please, drop us a line (wugulino at inf dot puc-rio dot br) about your research and how we can contribute to your benchmarking).</p>
<div id="detailed-accuracy" class="section level4">
<h4>Detailed Accuracy</h4>
<table>
<tbody>
<tr class="odd">
<td align="left">Correctly Classified Instances</td>
<td align="left">164662</td>
<td align="left">99.4144 %</td>
</tr>
<tr class="even">
<td align="left">Incorrectly Classified Instances</td>
<td align="left">970</td>
<td align="left">0.5856 %</td>
</tr>
<tr class="odd">
<td align="left">Root mean squared error</td>
<td align="left">0.0463</td>
</tr>
<tr class="even">
<td align="left">Relative absolute error</td>
<td align="left">0.7938 %</td>
</tr>
<tr class="odd">
<td align="left">Relative absolute error</td>
<td align="left">0.7938 %</td>
</tr>
</tbody>
</table>
</div>
<div id="detailed-accuracy-by-class" class="section level4">
<h4>Detailed Accuracy by Class</h4>
<table>
<thead>
<tr class="header">
<th align="left">TP Rate</th>
<th align="left">FP Rate</th>
<th align="left">Precision</th>
<th align="left">Recall</th>
<th align="left">F-Measure</th>
<th align="left">ROC Area</th>
<th align="left">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0.999</td>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">0.999</td>
<td align="left">0.999</td>
<td align="left">1</td>
<td align="left">Sitting</td>
</tr>
<tr class="even">
<td align="left">0.971</td>
<td align="left">0.002</td>
<td align="left">0.969</td>
<td align="left">0.971</td>
<td align="left">0.970</td>
<td align="left">0.999</td>
<td align="left">Sitting down</td>
</tr>
<tr class="odd">
<td align="left">0.999</td>
<td align="left">0.001</td>
<td align="left">0.998</td>
<td align="left">0.999</td>
<td align="left">0.999</td>
<td align="left">1</td>
<td align="left">Standing</td>
</tr>
<tr class="even">
<td align="left">0.962</td>
<td align="left">0.003</td>
<td align="left">0.969</td>
<td align="left">0.962</td>
<td align="left">0.965</td>
<td align="left">0.999</td>
<td align="left">Standing up</td>
</tr>
<tr class="odd">
<td align="left">0.998</td>
<td align="left">0.001</td>
<td align="left">0.998</td>
<td align="left">0.998</td>
<td align="left">0.998</td>
<td align="left">1</td>
<td align="left">Walking</td>
</tr>
<tr class="even">
<td align="left">0.994</td>
<td align="left">0.001</td>
<td align="left">0.994</td>
<td align="left">0.994</td>
<td align="left">0.994</td>
<td align="left">1</td>
<td align="left">Weighted Avg.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="weight-lifting-exercises-dataset" class="section level3">
<h3>Weight Lifting Exercises Dataset</h3>
<p>On-body sensing schema</p>
<p><img alt="On-body sensing schema" height="30%" src=./fig/On-bodySensingSchema.png width="30%"></p>
<p>This human activity recognition research has traditionally focused on discriminating between different activities, i.e. to predict “which” activity was performed at a specific point in time (like with the Daily Living Activities dataset above). The approach we propose for the Weight Lifting Exercises dataset is to investigate “how (well)” an activity was performed by the wearer. The “how (well)” investigation has only received little attention so far, even though it potentially provides useful information for a large variety of applications,such as sports training.</p>
<p>In this work (see the paper) we first define quality of execution and investigate three aspects that pertain to qualitative activity recognition: the problem of specifying correct execution, the automatic and robust detection of execution mistakes, and how to provide feedback on the quality of execution to the user. We tried out an on-body sensing approach (dataset here), but also an “ambient sensing approach” (by using Microsoft Kinect - dataset still unavailable)</p>
<p>Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).</p>
<p>Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. Participants were supervised by an experienced weight lifter to make sure the execution complied to the manner they were supposed to simulate. The exercises were performed by six male participants aged between 20-28 years, with little weight lifting experience. We made sure that all participants could easily simulate the mistakes in a safe and controlled manner by using a relatively light dumbbell (1.25kg).</p>
<p><em>This dataset is licensed under the Creative Commons (CC BY-SA)</em></p>
<p><em>Important: you are free to use this dataset for any purpose. This dataset is licensed under the Creative Commons license (CC BY-SA). The CC BY-SA license means you can remix, tweak, and build upon this work even for commercial purposes, as long as you credit the authors of the original work and you license your new creations under the identical terms we are licensing to you. This license is often compared to “copyleft” free and open source software licenses. All new works based on this dataset will carry the same license, so any derivatives will also allow commercial use.</em></p>
<p>Read more: <a href="http://groupware.les.inf.puc-rio.br/har#ixzz39cqEFN4F">http://groupware.les.inf.puc-rio.br/har#ixzz39cqEFN4F</a></p>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with --self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
